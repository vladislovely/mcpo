# âš¡ï¸ mcpo

Expose any MCP tool as an OpenAPI-compatible HTTP serverâ€”instantly.

mcpo is a dead-simple proxy that takes an MCP server command and makes it accessible via standard RESTful OpenAPI, so your tools "just work" with LLM agents and apps expecting OpenAPI servers.

No custom protocol. No glue code. No hassle.

## ğŸ¤” Why Use mcpo Instead of Native MCP?

MCP servers usually speak over raw stdio, which is:

- ğŸ”“ Inherently insecure
- âŒ Incompatible with most tools
- ğŸ§© Missing standard features like docs, auth, error handling, etc.

mcpo solves all of thatâ€”without extra effort:

- âœ… Works instantly with OpenAPI tools, SDKs, and UIs
- ğŸ›¡ Adds security, stability, and scalability using trusted web standards
- ğŸ§  Auto-generates interactive docs for every tool, no config needed
- ğŸ”Œ Uses pure HTTPâ€”no sockets, no glue code, no surprises

What feels like "one more step" is really fewer steps with better outcomes.

mcpo makes your AI tools usable, secure, and interoperableâ€”right now, with zero hassle.

## ğŸš€ Quick Usage

We recommend using uv for lightning-fast startup and zero config.

```bash
uvx mcpo --port 8000 --api-key "top-secret" -- your_mcp_server_command
```

Or, if youâ€™re using Python:

```bash
pip install mcpo
mcpo --port 8000 --api-key "top-secret" -- your_mcp_server_command
```

Example:

```bash
uvx mcpo --port 8000 --api-key "top-secret" -- uvx mcp-server-time --local-timezone=America/New_York
```

Thatâ€™s it. Your MCP tool is now available at http://localhost:8000 with a generated OpenAPI schema â€” test it live at [http://localhost:8000/docs](http://localhost:8000/docs).

### ğŸ”„ Using a Config File

You can serve multiple MCP tools via a single config file that follows the [Claude Desktop](https://modelcontextprotocol.io/quickstart/user) format:

Start via:

```bash
mcpo --config /path/to/config.json
```

Example config.json:

```json
{
  "mcpServers": {
    "memory": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-memory"]
    },
    "time": {
      "command": "uvx",
      "args": ["mcp-server-time", "--local-timezone=America/New_York"]
    }
  }
}
```

Each tool will be accessible under its own unique route, e.g.:
- http://localhost:8000/memory
- http://localhost:8000/time

Each with a dedicated OpenAPI schema and proxy handler. Access full schema UI at: `http://localhost:8000/<tool>/docs`  (e.g. /memory/docs, /time/docs)

## ğŸ”§ Requirements

- Python 3.8+
- uv (optional, but highly recommended for performance + packaging)

## ğŸªª License

MIT

## ğŸ¤ Contributing

We welcome and strongly encourage contributions from the community!

Whether you're fixing a bug, adding features, improving documentation, or just sharing ideasâ€”your input is incredibly valuable and helps make mcpo better for everyone.

Getting started is easy:

- Fork the repo
- Create a new branch
- Make your changes
- Open a pull request

Not sure where to start? Feel free to open an issue or ask a questionâ€”weâ€™re happy to help you find a good first task.

âœ¨ Let's build the future of interoperable AI tooling together!